{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaborative Filtering Recommender System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise\n",
    "\n",
    "With surprise Library, we will benchmark the following algorithms. We use \"rmse\" as our accuracy metric for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, \\\n",
    "    KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='item user rating', sep=',', skip_lines=1, rating_scale=(0.5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_file('ratings_cleaned.csv', reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD\n",
      "SVDpp\n",
      "SlopeOne\n",
      "NMF\n",
      "NormalPredictor\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "KNNBaseline\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "KNNWithMeans\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "KNNWithZScore\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "BaselineOnly\n",
      "CoClustering\n"
     ]
    }
   ],
   "source": [
    "algo_list = [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]\n",
    "benchmark = []\n",
    "\n",
    "for algo in algo_list:\n",
    "    results = cross_validate(algo=algo, data=data, measures=[\"rmse\"], cv=3, n_jobs=-1, verbose=False)\n",
    "    algo_name = str(algo).split(' ')[0].split('.')[-1]\n",
    "    print(algo_name)\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp['Algorithm'] = algo_name\n",
    "    benchmark.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>2.046756</td>\n",
       "      <td>0.137173</td>\n",
       "      <td>0.039502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>2.054566</td>\n",
       "      <td>0.052964</td>\n",
       "      <td>0.043458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>2.055028</td>\n",
       "      <td>1.837526</td>\n",
       "      <td>0.035611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>2.056549</td>\n",
       "      <td>0.297736</td>\n",
       "      <td>0.038188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>2.103320</td>\n",
       "      <td>1.167993</td>\n",
       "      <td>0.056383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>2.103425</td>\n",
       "      <td>2.274471</td>\n",
       "      <td>0.037356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>2.103482</td>\n",
       "      <td>1.959868</td>\n",
       "      <td>0.032777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>2.103501</td>\n",
       "      <td>0.569013</td>\n",
       "      <td>0.036005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>2.103728</td>\n",
       "      <td>1.582587</td>\n",
       "      <td>0.034793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>2.103797</td>\n",
       "      <td>1.491451</td>\n",
       "      <td>0.039500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>2.915239</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.043324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "SVDpp             2.046756  0.137173   0.039502\n",
       "BaselineOnly      2.054566  0.052964   0.043458\n",
       "KNNBaseline       2.055028  1.837526   0.035611\n",
       "SVD               2.056549  0.297736   0.038188\n",
       "NMF               2.103320  1.167993   0.056383\n",
       "KNNWithZScore     2.103425  2.274471   0.037356\n",
       "CoClustering      2.103482  1.959868   0.032777\n",
       "SlopeOne          2.103501  0.569013   0.036005\n",
       "KNNWithMeans      2.103728  1.582587   0.034793\n",
       "KNNBasic          2.103797  1.491451   0.039500\n",
       "NormalPredictor   2.915239  0.012849   0.043324"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Predict\n",
    "`SVDpp` algorithm gave us the best rmse, therefore, we will train and predict with `SVDpp`with a simple grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0378257716600316\n",
      "{'n_factors': 15, 'n_epochs': 25, 'lr_all': 0.012, 'reg_all': 0.02}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_factors': [15, 20, 25], \n",
    "              'n_epochs': [15, 20, 25], \n",
    "              'lr_all': [0.001, 0.007, 0.012],\n",
    "              'reg_all': [0.01, 0.02, 0.03]}\n",
    "\n",
    "gs = GridSearchCV(algo_class=SVDpp, param_grid=param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use these optimal hyperparameters to train your SVD model on the entire dataset and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.0153\n",
      "Test RMSE: 2.0152985009080933\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# Create an SVD algorithm with the best hyperparameters\n",
    "optimal_svd = SVDpp(n_factors=15, n_epochs=25, lr_all=0.012, reg_all=0.02)\n",
    "\n",
    "# Train the algorithm on the training set\n",
    "optimal_svd.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = optimal_svd.test(testset)\n",
    "\n",
    "# Evaluate the performance using RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect our predictions in details, we are going to build a pandas data frame with all the predictions. The following code were largely taken from this [notebook](http://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = df.uid.apply(get_Iu)\n",
    "df['Ui'] = df.iid.apply(get_Ui)\n",
    "df['err'] = abs(df.est - df.rui)\n",
    "best_predictions = df.sort_values(by='err')[:10]\n",
    "worst_predictions = df.sort_values(by='err')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "      <th>Iu</th>\n",
       "      <th>Ui</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>7699</td>\n",
       "      <td>166426</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.999426</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>7701</td>\n",
       "      <td>166426</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.999426</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>6365</td>\n",
       "      <td>242033</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000869</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>11209</td>\n",
       "      <td>493529</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.999038</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10059</td>\n",
       "      <td>550988</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.998880</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>5827</td>\n",
       "      <td>101299</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.003456</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>9536</td>\n",
       "      <td>425001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.004015</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>10491</td>\n",
       "      <td>628900</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.995820</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>7248</td>\n",
       "      <td>258489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.990688</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>6825</td>\n",
       "      <td>211672</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.013340</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid     iid  rui       est                    details  Iu  Ui  \\\n",
       "2370   7699  166426  6.0  5.999426  {'was_impossible': False}   0   1   \n",
       "378    7701  166426  6.0  5.999426  {'was_impossible': False}   0   1   \n",
       "1820   6365  242033  6.0  6.000869  {'was_impossible': False}   0   1   \n",
       "432   11209  493529  7.0  6.999038  {'was_impossible': False}   0   5   \n",
       "11    10059  550988  7.0  6.998880  {'was_impossible': False}   0   5   \n",
       "2207   5827  101299  6.0  6.003456  {'was_impossible': False}   0   2   \n",
       "1127   9536  425001  6.0  6.004015  {'was_impossible': False}   0   1   \n",
       "2632  10491  628900  6.0  5.995820  {'was_impossible': False}   0   2   \n",
       "2696   7248  258489  6.0  5.990688  {'was_impossible': False}   0   1   \n",
       "1740   6825  211672  6.0  6.013340  {'was_impossible': False}   0   1   \n",
       "\n",
       "           err  \n",
       "2370  0.000574  \n",
       "378   0.000574  \n",
       "1820  0.000869  \n",
       "432   0.000962  \n",
       "11    0.001120  \n",
       "2207  0.003456  \n",
       "1127  0.004015  \n",
       "2632  0.004180  \n",
       "2696  0.009312  \n",
       "1740  0.013340  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In collaborative filtering, the small values in the **err** column also imply a high level of confidence in the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "      <th>Iu</th>\n",
       "      <th>Ui</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>3028</td>\n",
       "      <td>686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.076706</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.076706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>7856</td>\n",
       "      <td>346364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.137821</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.137821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>8877</td>\n",
       "      <td>474350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.142201</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6.142201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>796</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.168850</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.168850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>6977</td>\n",
       "      <td>334541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.204771</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.204771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2718</td>\n",
       "      <td>9598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.222246</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.222246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>4064</td>\n",
       "      <td>6171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.249354</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.249354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>10152</td>\n",
       "      <td>370172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.284259</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.284259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>11547</td>\n",
       "      <td>466420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.314201</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.314201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>11202</td>\n",
       "      <td>603692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.377509</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.377509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid     iid  rui       est                    details  Iu  Ui  \\\n",
       "506    3028     686  1.0  7.076706  {'was_impossible': False}   0   3   \n",
       "1040   7856  346364  1.0  7.137821  {'was_impossible': False}   0   4   \n",
       "2832   8877  474350  1.0  7.142201  {'was_impossible': False}   0   7   \n",
       "744     796      28  1.0  7.168850  {'was_impossible': False}   0   4   \n",
       "2215   6977  334541  1.0  7.204771  {'was_impossible': False}   0   2   \n",
       "202    2718    9598  1.0  7.222246  {'was_impossible': False}   0   1   \n",
       "2566   4064    6171  1.0  7.249354  {'was_impossible': False}   0   1   \n",
       "2493  10152  370172  1.0  7.284259  {'was_impossible': False}   0   5   \n",
       "2531  11547  466420  1.0  7.314201  {'was_impossible': False}   0   5   \n",
       "88    11202  603692  1.0  7.377509  {'was_impossible': False}   0  11   \n",
       "\n",
       "           err  \n",
       "506   6.076706  \n",
       "1040  6.137821  \n",
       "2832  6.142201  \n",
       "744   6.168850  \n",
       "2215  6.204771  \n",
       "202   6.222246  \n",
       "2566  6.249354  \n",
       "2493  6.284259  \n",
       "2531  6.314201  \n",
       "88    6.377509  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst predictions, as indicated by the provided data, highlight instances where the recommender system struggled to accurately estimate user ratings for certain items. In these cases, the predicted ratings significantly deviated from the actual ratings, resulting in comparatively high error values.\n",
    "\n",
    "Understanding and addressing these challenges can pave the way for further improvements in recommender systems. Techniques such as incorporating more advanced algorithms, enhancing data preprocessing, or exploring hybrid models that combine collaborative and content-based filtering approaches could contribute to refining predictions and delivering more accurate recommendations to users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
